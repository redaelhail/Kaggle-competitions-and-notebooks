{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese neural network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOA2f8KMdjb0fC+wwuqqO3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redaelhail/Kaggle-competitions-and-notebooks/blob/main/Siamese_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bnWWP85UC5TH"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "import os\n",
        "# specify the shape of the inputs for our network\n",
        "IMG_SHAPE = (28, 28, 1)\n",
        "# specify the batch size and number of epochs\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D"
      ],
      "metadata": {
        "id": "mwhMjzBVHOBw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, embedDim=48):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\", input_shape=input_shape)(inputs)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(32, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(16, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    outputs = Flatten()(x)\n",
        "    outputs = Dense(embedDim)(outputs)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cU49W3bMC80f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "amGGFladHRFX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pairs(images, labels):\n",
        "\t# initialize two empty lists to hold the (image, image) pairs and\n",
        "\t# labels to indicate if a pair is positive or negative\n",
        "\tpairImages = []\n",
        "\tpairLabels = []\n",
        "\t# calculate the total number of classes present in the dataset\n",
        "\t# and then build a list of indexes for each class label that\n",
        "\t# provides the indexes for all examples with a given label\n",
        "\tnumClasses = len(np.unique(labels))\n",
        "\tidx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
        "\t# loop over all images\n",
        "\tfor idxA in range(len(images)):\n",
        "\t\t# grab the current image and label belonging to the current\n",
        "\t\t# iteration\n",
        "\t\tcurrentImage = images[idxA]\n",
        "\t\tlabel = labels[idxA]\n",
        "\t\t# randomly pick an image that belongs to the *same* class\n",
        "\t\t# label\n",
        "\t\tidxB = np.random.choice(idx[label])\n",
        "\t\tposImage = images[idxB]\n",
        "\t\t# prepare a positive pair and update the images and labels\n",
        "\t\t# lists, respectively\n",
        "\t\tpairImages.append([currentImage, posImage])\n",
        "\t\tpairLabels.append([1])\n",
        "\t\t# grab the indices for each of the class labels *not* equal to\n",
        "\t\t# the current label and randomly pick an image corresponding\n",
        "\t\t# to a label *not* equal to the current label\n",
        "\t\tnegIdx = np.where(labels != label)[0]\n",
        "\t\tnegImage = images[np.random.choice(negIdx)]\n",
        "\t\t# prepare a negative pair of images and update our lists\n",
        "\t\tpairImages.append([currentImage, negImage])\n",
        "\t\tpairLabels.append([0])\n",
        "\t# return a 2-tuple of our image pairs and labels\n",
        "\treturn (np.array(pairImages), np.array(pairLabels))"
      ],
      "metadata": {
        "id": "nJvYrUiZHNLw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vectors):\n",
        "\t# unpack the vectors into separate lists\n",
        "\t(featsA, featsB) = vectors\n",
        "\t# compute the sum of squared distances between the vectors\n",
        "\tsumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
        "\t\tkeepdims=True)\n",
        "\t# return the euclidean distance between the vectors\n",
        "\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))"
      ],
      "metadata": {
        "id": "_FydGIoxHnMf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training(H, plotPath):\n",
        "    # construct a plot that plots and saves the training history\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.savefig(plotPath)"
      ],
      "metadata": {
        "id": "JcNUc8v1Hq4f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "khjnGIS5H-nC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load MNIST dataset and scale the pixel values to the range of [0, 1]\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "# add a channel dimension to the images\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "# prepare the positive and negative pairs\n",
        "print(\"[INFO] preparing positive and negative pairs...\")\n",
        "(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
        "(pairTest, labelTest) = make_pairs(testX, testY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezr1bVWkHxJR",
        "outputId": "8a97a7a2-285a-4510-de0f-24e3de2a7f2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "[INFO] preparing positive and negative pairs...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configure the siamese network\n",
        "print(\"[INFO] building siamese network...\")\n",
        "imgA = Input(shape=IMG_SHAPE)\n",
        "imgB = Input(shape=IMG_SHAPE)\n",
        "featureExtractor = build_model(IMG_SHAPE)\n",
        "featsA = featureExtractor(imgA)\n",
        "featsB = featureExtractor(imgB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzOXyY-hIQ0t",
        "outputId": "28ffc0b2-989a-4849-9756-ee7d2f3ce783"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] building siamese network...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, construct the siamese network\n",
        "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
        "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
        "model = Model(inputs=[imgA, imgB], outputs=outputs)"
      ],
      "metadata": {
        "id": "dl_S28lxIipt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgTXqZJCLYns",
        "outputId": "303b340f-c72b-460b-a220-3d34ca4afca3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_13 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " model_9 (Functional)           (None, 48)           17568       ['input_13[0][0]',               \n",
            "                                                                  'input_14[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1)            0           ['model_9[0][0]',                \n",
            "                                                                  'model_9[1][0]']                \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 1)            2           ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,570\n",
            "Trainable params: 17,570\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(\n",
        "    [pairTrain[:, 0], pairTrain[:, 1]], labelTrain,\n",
        "    validation_data=[[pairTest[:, 0], pairTest[:, 1]], labelTest],\n",
        "    batch_size=64,\n",
        "    epochs=1\n",
        ")\n",
        "\n",
        "model.save(\"output/siamese_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8N0M_MzDg9N",
        "outputId": "e7bca402-a547-4ec2-f382-65fffbde8288"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 283s 151ms/step - loss: 0.0000e+00 - accuracy: 0.4999 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "INFO:tensorflow:Assets written to: output/siamese_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PzejLC0iHv-W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8WpsI3TJDkDd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}